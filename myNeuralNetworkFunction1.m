function [y1] = myNeuralNetworkFunction1(x1)
%MYNEURALNETWORKFUNCTION neural network simulation function.
%
% Generated by Neural Network Toolbox function genFunction, 05-May-2018 11:03:02.
%
% [y1] = myNeuralNetworkFunction(x1) takes these arguments:
%   x = 2xQ matrix, input #1
% and returns:
%   y = 4xQ matrix, output #1
% where Q is the number of samples.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Input 1
x1_step1.xoffset = [-0.392732717567874;-0.389840038768807];
x1_step1.gain = [1.11602140113636;1.12719358184917];
x1_step1.ymin = -1;

% Layer 1
b1 = [2.4176417998312156321;2.2049166513709534954;-1.9909803592978019271;1.0647577030132380216;-0.18116733815754285097;-1.2060084705681846096;0.29318651921386701398;2.2704350183008910058;-0.044487749642151609708;-4.3970336982039581741];
IW1_1 = [-4.0772634180025626449 -4.166900999545968709;-4.2731606964053856501 3.847022409860827441;3.6665392739563267277 -3.7699809652999030085;-6.9334640161307339312 -1.7551946142546219765;-0.37341468254902437929 5.623357818750303494;-2.0338106365336319215 -4.4926525822756495643;5.0633351511094577546 0.41847357901514053991;3.2014461940886378422 3.7378632636910689158;-0.015139725783475022416 5.642344503592016558;-0.40951546939457394991 -4.4725214089272640194];

% Layer 2
b2 = [-0.084113510704636268445;-0.30413107368794223273;0.57848908430081835697;0.22579354257279088403];
LW2_1 = [0.65462388635446733254 2.022402280985089007 -2.2115360702126873882 1.2390404809863058144 -3.156756372177010217 2.5292722630300792375 -3.2186316578457172533 -2.9360921565695936586 -1.6455307806849861496 0.11174571937430970159;0.61745764541141945347 -0.17930256617814799291 -1.1494951136392166369 5.1715180440729602296 4.7016155311011056384 -1.9351263746436542235 -2.011914978062006476 1.1385166642659798608 1.224215422546654386 1.5282959593262714915;2.0350589127606473205 -2.8353469839855853785 2.8401900965449398129 0.17737944788502682525 -2.8530802393923089255 -0.8931905815828258266 1.7151484896022315407 1.928366911435498432 -1.6277171400252881117 -0.64776673216040281389;-1.7068079587356537186 2.0159144357082920962 -1.9172244368753696975 -6.3989918044940301556 1.7652381776739347607 -0.25458310635250025467 1.2032239411888525638 1.2714956929104479499 1.0140127673738681402 0.79053396601600445237];

% ===== SIMULATION ========

% Dimensions
Q = size(x1,2); % samples

% Input 1
xp1 = mapminmax_apply(x1,x1_step1);

% Layer 1
a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*xp1);

% Layer 2
a2 = softmax_apply(repmat(b2,1,Q) + LW2_1*a1);

% Output 1
y1 = a2;
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings)
y = bsxfun(@minus,x,settings.xoffset);
y = bsxfun(@times,y,settings.gain);
y = bsxfun(@plus,y,settings.ymin);
end

% Competitive Soft Transfer Function
function a = softmax_apply(n,~)
if isa(n,'gpuArray')
    a = iSoftmaxApplyGPU(n);
else
    a = iSoftmaxApplyCPU(n);
end
end
function a = iSoftmaxApplyCPU(n)
nmax = max(n,[],1);
n = bsxfun(@minus,n,nmax);
numerator = exp(n);
denominator = sum(numerator,1);
denominator(denominator == 0) = 1;
a = bsxfun(@rdivide,numerator,denominator);
end
function a = iSoftmaxApplyGPU(n)
nmax = max(n,[],1);
numerator = arrayfun(@iSoftmaxApplyGPUHelper1,n,nmax);
denominator = sum(numerator,1);
a = arrayfun(@iSoftmaxApplyGPUHelper2,numerator,denominator);
end
function numerator = iSoftmaxApplyGPUHelper1(n,nmax)
numerator = exp(n - nmax);
end
function a = iSoftmaxApplyGPUHelper2(numerator,denominator)
if (denominator == 0)
    a = numerator;
else
    a = numerator ./ denominator;
end
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n,~)
a = 2 ./ (1 + exp(-2*n)) - 1;
end
