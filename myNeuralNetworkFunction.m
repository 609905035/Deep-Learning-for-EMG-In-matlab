function [y1] = myNeuralNetworkFunction(x1)
%MYNEURALNETWORKFUNCTION neural network simulation function.
%
% Generated by Neural Network Toolbox function genFunction, 05-May-2018 09:58:38.
%
% [y1] = myNeuralNetworkFunction(x1) takes these arguments:
%   x = 4xQ matrix, input #1
% and returns:
%   y = 3xQ matrix, output #1
% where Q is the number of samples.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Input 1
x1_step1.xoffset = [4.3;2;1;0.1];
x1_step1.gain = [0.555555555555555;0.833333333333333;0.338983050847458;0.833333333333333];
x1_step1.ymin = -1;

% Layer 1
b1 = [-1.8249986765373897857;-1.7055245485376309134;1.1446593515841108069;0.27106071773949858006;-0.1016160882660494813;0.62676654650532626079;0.9681657358199372565;1.5180636607374042857;-1.8960928291102709942;2.55674785704142149];
IW1_1 = [1.7111349014562486914 0.74270137636938526882 0.48382125754417265595 2.3133093788443983563;1.309090325410985356 -1.6074665153921674499 0.89399738112117599353 -1.171692705402861856;-0.79333294974927981436 -1.2181826745443951054 1.5526026828495775867 1.6764728734342364547;0.26293907516534159585 -0.13915629916207897243 2.8695964748799340782 -0.1675521927099652697;-0.33502111161422187813 2.2166858077124818038 -0.029613414060503107095 -1.5243129820647449701;0.77409081216328334829 -0.58894455430220882253 -2.0109756149392685742 -1.4656015228449392751;0.75765703902540371129 0.39730947158206975089 -2.6757643377699915632 -0.1674170441647844787;1.5408330778520125115 -1.521383717844891903 -1.1501402854309397128 0.10985724083845418986;-1.1027674442028958524 1.2216240556551276608 1.7233229773353875292 -0.70806570496269694015;0.82679089205195954726 -1.1647200609150791806 -1.2647266933983942749 1.5346854807962029277];

% Layer 2
b2 = [-0.75243676472866893867;0.70138910667110698771;-0.35956764356701537144];
LW2_1 = [0.28224552176485012689 -0.32455036884525473306 -1.3110896570575265585 -1.9262918803495718834 1.7459963680789092333 0.53123469386959887295 -0.30610993075169079525 -0.15233350280795202036 -0.26018990662145918824 0.21403994729959746612;-0.44706838847844876383 0.53022836058177058582 0.52402456958110554819 0.1804731377464450226 -0.50874204193459449108 0.50005721154972304632 0.8769329590928802709 -0.64537505195149125203 0.4096241144605561324 -0.19044044336381640847;1.2691855932609463764 0.38785869268266431886 -0.16469135799629658345 1.4736485461583084255 -0.97177321899410307182 -2.3944611955026644523 -1.0354592464972800503 0.39003616757470371823 0.063095564474771645425 -0.45857036528950168019];

% ===== SIMULATION ========

% Dimensions
Q = size(x1,2); % samples

% Input 1
xp1 = mapminmax_apply(x1,x1_step1);

% Layer 1
a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*xp1);

% Layer 2
a2 = softmax_apply(repmat(b2,1,Q) + LW2_1*a1);

% Output 1
y1 = a2;
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings)
y = bsxfun(@minus,x,settings.xoffset);
y = bsxfun(@times,y,settings.gain);
y = bsxfun(@plus,y,settings.ymin);
end

% Competitive Soft Transfer Function
function a = softmax_apply(n,~)
if isa(n,'gpuArray')
    a = iSoftmaxApplyGPU(n);
else
    a = iSoftmaxApplyCPU(n);
end
end
function a = iSoftmaxApplyCPU(n)
nmax = max(n,[],1);
n = bsxfun(@minus,n,nmax);
numerator = exp(n);
denominator = sum(numerator,1);
denominator(denominator == 0) = 1;
a = bsxfun(@rdivide,numerator,denominator);
end
function a = iSoftmaxApplyGPU(n)
nmax = max(n,[],1);
numerator = arrayfun(@iSoftmaxApplyGPUHelper1,n,nmax);
denominator = sum(numerator,1);
a = arrayfun(@iSoftmaxApplyGPUHelper2,numerator,denominator);
end
function numerator = iSoftmaxApplyGPUHelper1(n,nmax)
numerator = exp(n - nmax);
end
function a = iSoftmaxApplyGPUHelper2(numerator,denominator)
if (denominator == 0)
    a = numerator;
else
    a = numerator ./ denominator;
end
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n,~)
a = 2 ./ (1 + exp(-2*n)) - 1;
end
